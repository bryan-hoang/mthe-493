\providecommand{\main}{..}
\documentclass[../mthe-493-project-proposal.tex]{subfiles}

% Introduction/Background: This is essentially the project descriptions sent out in September. Fine-tune it to be more specific to your application, as decided upon with your supervisor. Make sure you show understanding when you include technical content. Most of you will have done some background research. Include the relevant theory / research, but you do not need to include proofs or pages of equations.
\begin{document}
    \chapter{Introduction/Background}
    \label{ch:introduction}

    Edge computing is an emerging paradigm for IoT and data analytics systems. It is a method of performing computationally heavy tasks that does the work on end-user devices. These systems can scale well and can drastically simplify infrastructure provisioning. Additionally, edge computing minimizes that amount of data required to be sent back and forth, since the work is done right on the device. With global industry embracing smart architecture and IoT processes, the edge-computing market is predicted to grow to \$43.4 billion by 2027, by which time 75\% of enterprise-generated data will be created and processed at the edge.~\cite{noauthor_edge_2020}
    
    In many of its applications, such as image recognition, forecasting, and clustering, Machine Learning (ML) has outperformed existing techniques. This has motivated the need to deploy computationally dense ML models on end devices. One area of ML where substantial momentum has been gained is in Distributed Learning (DL). This is the method of training of a ML model by aggregating many local models which are trained on edge devices. Federated learning (FL) is similar to distributed learning, but stores the data on edge devices. In this case, the edge nodes are typically where training data is collected, such as a sensor on a smartphone. The focus of this project will be parallel learning (PL), where data begins in a central orchestrator and distributes it to edge devices for training.
    
    When attempting to optimally configure a distributed computing network for PL, one must consider two important variables, network costs and computational capabilities. When there are differences in the network costs and computational capabilities of edge devices, this is called system heterogeneity, and it makes creating an optimal configuration substantially more difficult. If heterogeneity is not addressed, distributed learning performance is limited by its weakest edge or slowest connection. There are two approaches to circumvent heterogeneity. One can either vary the volume of data sent to each edge, or vary the number of local training iterations performed on each edge. The latter is often less accurate due to a discrepancy created in edge gradients that is referred to as 'staleness'. This project will perform experiments with both methods.
    
    % (NOTE: The following is from Sara's document. I think we should use this and adapt it as a intro/background)

    % Edge computing is proving to be a successful paradigm for dealing with the computational challenges raised by the era of the Internet of Everything (IoE). With the world embracing smart architectures, including smart cities, smart grids, smart homes, etc., it is expected that 41 billion IoT devices will be online by 2027, generating around 800 zettabytes of data [1]. This will place a heavy burden on backhaul links and raise security/privacy concerns. Thus, it is anticipated that edge servers and end devices, such as smart phones, cameras, drones, etc., will perform 90\% of analytics locally [2].

    % Machine Learning (ML) techniques have shown superior performance in many data analytics applications, such as forecasting, image classification, clustering, etc. Therefore, researchers have turned their attention to deploying ML models on end devices as part of the Edge Artificial Intelligence (Edge AI). Performing ML in a distributed manner (a.k.a. distributed learning (DL)) at the edge has gained significant momentum lately. DL enables the training of a global learning model from the local models that are concurrently trained at multiple mobile edge devices. DL branches into two major practical settings, namely the federated and parallelized learning. Both scenarios involve the presence of a governing node, known as the orchestrator, and a number of helping nodes known as learners. The orchestrator aims to train the global model by running local training cycles of the same model at the learners and aggregating their learning outcomes. The difference between the two scenarios lies in the location of the data. In federated learning (FL), different datasets are already stored at the different learners. In parallelized learning (PL), the orchestrator initially possesses the entire dataset and decides to distribute fragments of it to learners for learning purposes.

    % In DL, heterogeneity among learners poses a major problem. Such heterogeneity refers to the different computation and communication characteristics of the recruited learners. Failure to address system heterogeneity limits DL to the performance of its weakest learner. In order to resolve this issue, some schemes allocate different amounts of data to each learner, while others allow learners to perform variable number of local iterations [3] [4]. The latter approach can reduce the training accuracy since it increases the discrepancy or ’staleness’ among the gradients of each learner. Thus, in order to reduce staleness, we implement a resource allocation scheme that addresses system heterogeneity in DL by allocating different amount of data to each learner. The details and methodology of this scheme are provided below.
\end{document}
